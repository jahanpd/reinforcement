{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Symbol     Open     High      Low    Close  Volume BTC  \\\n",
      "0  2019-06-21  BTCUSD  9531.21  9751.00  9531.21  9751.00     1689.53   \n",
      "1  2019-06-20  BTCUSD  9277.54  9599.00  9210.30  9531.21    11555.59   \n",
      "2  2019-06-19  BTCUSD  9078.48  9319.50  9035.75  9277.54     9173.83   \n",
      "3  2019-06-18  BTCUSD  9333.14  9359.48  8919.72  9078.48    15974.31   \n",
      "4  2019-06-17  BTCUSD  8975.00  9475.00  8975.00  9333.14    20193.67   \n",
      "\n",
      "     Volume USD  \n",
      "0  1.625413e+07  \n",
      "1  1.088499e+08  \n",
      "2  8.402408e+07  \n",
      "3  1.457857e+08  \n",
      "4  1.870674e+08  \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "from multiprocessing.dummy import Pool\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sumtree import SumTree, perfect_run, random_run\n",
    "\n",
    "# generate generic dataseries of 'price' movements over a 130 day period\n",
    "data = pd.read_csv(\"btcusd.csv\")\n",
    "print(data.head())\n",
    "data = np.flip(data.Close.values)\n",
    "data = data.reshape(len(data),1)\n",
    "scaler = MinMaxScaler()\n",
    "scaler = scaler.fit(data)\n",
    "data = scaler.transform(data)\n",
    "data = data.reshape(1,len(data))[0] + 1\n",
    "test = data[-365:]\n",
    "data = data[:-356]\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jahan/.conda/envs/data2/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:Output \"y_pred\" missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to \"y_pred\".\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prices_in (InputLayer)       (None, 60, 1)             0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 60, 60)            11160     \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 60, 60)            21780     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 60, 60)            21780     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "y_pred (Dense)               (None, 2)                 7202      \n",
      "=================================================================\n",
      "Total params: 61,922\n",
      "Trainable params: 61,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /home/jahan/.conda/envs/data2/lib/python3.7/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prices_in (InputLayer)       (None, 60, 1)             0         \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 60, 60)            11160     \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 60, 60)            21780     \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (None, 60, 60)            21780     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "y_pred (Dense)               (None, 2)                 7202      \n",
      "=================================================================\n",
      "Total params: 61,922\n",
      "Trainable params: 61,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# custom loss function as per https://www.freecodecamp.org/news/improvements-in-deep-q-learning-dueling-double-dqn-prioritized-experience-replay-and-fixed-58b130cc5682/\n",
    "\n",
    "def IS(y_true, y_pred, is_weight):\n",
    "    return is_weight * keras.losses.mean_squared_error(y_true, y_pred)\n",
    "    \n",
    "\n",
    "# build deep recurrent model with keras and LSTM\n",
    "def buildmodel(is_train):\n",
    "    x = keras.layers.Input(shape=(60,1), name=\"prices_in\")\n",
    "    y_true = keras.layers.Input(shape=(2,), name=\"y_true\")\n",
    "    if is_train:\n",
    "        is_weight = keras.layers.Input(shape=(1,), name=\"is_weight\")\n",
    "    f = keras.layers.GRU(60, return_sequences=True)(x)\n",
    "    f = keras.layers.GRU(60, return_sequences=True)(f)\n",
    "    f = keras.layers.GRU(60, return_sequences=True)(f)\n",
    "    f = keras.layers.Flatten()(f)\n",
    "    y_pred = keras.layers.Dense(2, activation=tf.nn.leaky_relu, name=\"y_pred\")(f)\n",
    "    if is_train:\n",
    "        model = keras.models.Model(inputs = [x,y_true,is_weight], outputs=y_pred, name=\"train_only\")\n",
    "        model.add_loss(IS(y_true, y_pred, is_weight))\n",
    "        model.compile(loss=None, optimizer=\"adam\")\n",
    "        print(model.summary())\n",
    "    else:\n",
    "        model = keras.models.Model(inputs = x, outputs=y_pred, name=\"predict\")\n",
    "        model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "        print(model.summary())\n",
    "    \n",
    "    return model\n",
    "\n",
    "# call model\n",
    "model_train = buildmodel(is_train=True)\n",
    "model_predict = buildmodel(is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04407758 0.00122013]]\n",
      "0\n",
      "0.04407758\n"
     ]
    }
   ],
   "source": [
    "#print(np.expand_dims(np.array([data[0:60]]),2).reshape(60,1))\n",
    "print(model_predict.predict(np.expand_dims(np.array([data[0:60]]),2)))\n",
    "print(np.argmax(model_predict.predict(np.expand_dims(np.array([data[0:60]]),2))))\n",
    "print(np.max(model_predict.predict(np.expand_dims(np.array([data[0:60]]),2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to process dataframe to run through above\n",
    "def prep_targets(pred_s,pred_s1,a_vals,r_vals ):\n",
    "    y =np.empty([0,2])\n",
    "    for i in range(len(a_vals)):\n",
    "        a = a_vals[i]\n",
    "        r = r_vals[i]\n",
    "        if a == 0: # if action is sell\n",
    "            temp = [r + 0.9*np.max(pred_s1[i]), pred_s[i][1]]\n",
    "        else: # if a == 1 aka buy\n",
    "            temp = [pred_s[i][1],r + 0.9*np.max(pred_s1[i])]\n",
    "        y = np.append(y,np.array(temp))       \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# cell to design training function\n",
    "\n",
    "# there are 2^step possible sets of choices. We'll start random walking, \n",
    "# training our algorithm stochastically,\n",
    "# as well as batch learning once our experience replay dict get large enough\n",
    "\n",
    "# inputs to function are as follows\n",
    "# epoch is number of cycles\n",
    "# batch_size is size of batch to train from experience replay dataset\n",
    "# mod is reward modifier \n",
    "# gamma is gamma setting\n",
    "# prob is random walk probability\n",
    "\n",
    "\n",
    "\n",
    "def training_function(epoch,batch_size,step,mod,gamma,prob):\n",
    "    # dataframe to save experience replay shenanigans\n",
    "    replay = SumTree(100*len(data)-step)\n",
    "    # training metrics\n",
    "    losses = [0]\n",
    "    values = np.empty([0,len(data)-step])\n",
    "    perfection, full = perfect_run(1, data) # generate a 'perfect run' to compare against\n",
    "    randomness = random_run(10, data)\n",
    "    values = np.append(values, np.mean(np.array(randomness), axis=0))\n",
    "    values = np.append(values, np.array(full))\n",
    "    # initialise eta parameter\n",
    "    eta = 0\n",
    "    epoch_time = 0\n",
    "    small = True # value for checking whether to do batch learn\n",
    "    # start epoch loop\n",
    "    for its in range(epoch):\n",
    "        # start recording time\n",
    "        loop_start = time.time()\n",
    "        \n",
    "        # loss addition parameter\n",
    "        loss = 0\n",
    "        \n",
    "        # arrays to store values of portfolio to generate rewards from\n",
    "        cash = [1000]\n",
    "        position = [0]\n",
    "        value =[1000]\n",
    "        \n",
    "        # start random/qvalue walk through timeseries data w step day slices\n",
    "        for t in range(len(data)- step):\n",
    "            if small:\n",
    "                clear_output(wait=True)\n",
    "            \n",
    "            # define current environment/state (s) and next environment (s1)\n",
    "            s = data[t:t+step]\n",
    "            s_trans = np.expand_dims(np.array([s]),2) # transformed for feeding into model\n",
    "            s1 = data[t+1:t+step+1]\n",
    "            s1_trans = np.expand_dims(np.array([s1]),2)\n",
    "            # update cash and position metrics\n",
    "            def a_is_0():\n",
    "                if cash[-1] == 0:\n",
    "                    cash.append(position[-1]*s[-1] - 10)\n",
    "                    position.append(0)\n",
    "                    value.append(cash[-1])\n",
    "                else:\n",
    "                    cash.append(cash[-1])\n",
    "                    position.append(0)\n",
    "                    #opportunity_cost = s[-1]/s1[-1] \n",
    "                    value.append(value[-1])\n",
    "            def a_is_1():\n",
    "                if position[-1] == 0:\n",
    "                    position.append((cash[-1] - 10)/s[-1])\n",
    "                    cash.append(0)\n",
    "                    value.append(position[-1]*s[-1])\n",
    "                else:\n",
    "                    position.append(position[-1])\n",
    "                    value.append(position[-1]*s[-1])\n",
    "            \n",
    "            # chance of random action rather than action by bigger Q score\n",
    "            if random.uniform(0,1) < prob:\n",
    "                # random walk\n",
    "                a = np.random.choice([0,1])\n",
    "                if a == 0:\n",
    "                    a_is_0()\n",
    "                    # r is defined by the change in the value of the portforlio\n",
    "                    r = mod * ((value[-1] - value[-2])/value[-1])\n",
    "                else:\n",
    "                    a_is_1()\n",
    "                    r = mod * ((value[-1] - value[-2])/value[-1])\n",
    "            # choose action by max Q score\n",
    "            else:\n",
    "                a = np.argmax(model_predict.predict(s_trans)[0])\n",
    "                if a == 0:\n",
    "                    a_is_0()\n",
    "                    r = mod * ((value[-1] - value[-2])/value[-1])\n",
    "                else:\n",
    "                    a_is_1()\n",
    "                    r = mod * ((value[-1] - value[-2])/value[-1])\n",
    "            \n",
    "            # generation array of predicted qvalues from current state\n",
    "            qs = model_predict.predict(s_trans)[0]\n",
    "            # get max qvalue from next state\n",
    "            maxqs1 = np.max(model_predict.predict(s1_trans)[0])\n",
    "            \n",
    "            # set targets for training/backprop depending on action taken\n",
    "            # also generate Pt value (for priority replay training when selecting batch)\n",
    "            if a == 0: # if action is sell\n",
    "                target = [r + gamma*maxqs1, qs[1]]\n",
    "                Pt = abs(qs[0] - (r + gamma*maxqs1)) + 0.001\n",
    "            else: # if a == 1 aka buy\n",
    "                target = [qs[0],r + gamma*maxqs1]\n",
    "                Pt = abs(qs[1] - (r + gamma*maxqs1))+0.001\n",
    "            \n",
    "            # store values in sumtree\n",
    "            store = list(s) + [s1[-1]] + [a] + [r]\n",
    "            replay.add(Pt, np.array(store))\n",
    "            \n",
    "            if small:\n",
    "                print(\"epoch:\",its,\" step:\", t, \"loss: {:.2f}\".format(losses[-1]),\n",
    "                      \"value:{:.2f}\".format(np.mean(value)),\n",
    "                      \"memory usage:{:.2f}mb\".format(replay.memory()/1000000))\n",
    "\n",
    "            # do forward pass of training on current inputs\n",
    "            loss += model_train.train_on_batch([s_trans, np.array([target]), np.array([1])])\n",
    "            model_predict.set_weights(model_train.get_weights())\n",
    "            \n",
    "            # this is to learn from replay experience memory\n",
    "            # batch learning w batch_size samples if number of samples reaches batch_size\n",
    "            tmod = (t % 10) == 0\n",
    "            if small:\n",
    "                if np.count_nonzero(replay.p_array()) > batch_size:\n",
    "                    small = False\n",
    "            if (not small) and tmod:\n",
    "                prob = 0.1\n",
    "                # prepare data\n",
    "                print(\"prepare dataframe\")\n",
    "                replay.normalise() # to normalise probabilities from 0-1 of getting picked\n",
    "                p_array = replay.p_array() # generate prob array\n",
    "                sample = np.random.choice(p_array,batch_size,replace=False,p=p_array)\n",
    "                x = np.empty([0,step])\n",
    "                state1 = np.empty([0,step])\n",
    "                a = np.empty([0,1])\n",
    "                r = np.empty([0,1])\n",
    "                is_weight = np.empty([0,1])\n",
    "                ids = np.empty([0,1])\n",
    "                for i in range(batch_size):\n",
    "                    idx, p_value, data_array = replay.get(sample[i])\n",
    "                    x = np.append(x,data_array[0:step])\n",
    "                    state1 = np.append(state1,data_array[1:step+1])\n",
    "                    a = np.append(a,[data_array[-2]])\n",
    "                    r = np.append(r,[data_array[-1]])\n",
    "                    is_weight = np.append(is_weight,[np.power(1/(np.count_nonzero(p_array)*p_value),(its/epoch))])\n",
    "                    ids = np.append(ids,[idx])\n",
    "                # print(is_weight[1:10])\n",
    "                \n",
    "                replay.unnormalise() # restore Pts\n",
    "                # batch predict for speed\n",
    "                x = np.expand_dims(x.reshape([batch_size,step]),2) #reshape and state1\n",
    "                state1 = np.expand_dims(state1.reshape([batch_size,step]),2)\n",
    "                \n",
    "                qs1 = model_predict.predict(state1) # make q value table for state (x) and state 1\n",
    "                Qs = model_predict.predict(x)\n",
    "                                \n",
    "                y = prep_targets(Qs,qs1, a, r)\n",
    "                y = y.reshape([batch_size,2]) # y reshape for LSTM input\n",
    "                \n",
    "                clear_output(wait=True)\n",
    "                batch_size\n",
    "                print(\"epoch:\",its,\" step:\", t, \"loss: {:.2f}\".format(losses[-1]),\n",
    "                      \"cur_value:{:.2f}\".format(value[-1]),\n",
    "                      \"memory usage:{:.2f}mb\".format(replay.memory()/1000000),\n",
    "                      \"eta:{:.2f}mins\".format(eta/step))\n",
    "                print(a[-1],Qs[-1],r[-1],((r[-1] + gamma*np.max(qs1[-1]))))\n",
    "    \n",
    "                model_train.fit([x,y,is_weight]) # fit model on batch\n",
    "                model_predict.set_weights(model_train.get_weights()) # sync weights\n",
    "                \n",
    "            eta = (epoch_time * (epoch - its)) - epoch_time*(t/(len(data) - step))\n",
    "        losses.append(loss[0][0])\n",
    "        values = np.append(values, np.array(value))\n",
    "        np.savetxt('prog.out', np.array(values), delimiter=',')\n",
    "        epoch_time = time.time()-loop_start\n",
    "    return losses, values, replay\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  step: 440 loss: 0.00 cur_value:1000.27 memory usage:3.11mb eta:0.00mins\n",
      "0.0 [ 1.5610757  -0.07731184] 0.0 1.4049455881118775\n",
      "288/320 [==========================>...] - ETA: 0s - loss: 0.6047"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-be4528dda447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                     \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                                     \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                                                    )\n",
      "\u001b[0;32m<ipython-input-9-6d5dcabb47e3>\u001b[0m in \u001b[0;36mtraining_function\u001b[0;34m(epoch, batch_size, step, mod, gamma, prob)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mQs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqs1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                 \u001b[0mmodel_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mis_weight\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# fit model on batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m                 \u001b[0mmodel_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# sync weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/data2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.conda/envs/data2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/data2/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/.conda/envs/data2/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_array, value_array, memory = training_function(epoch=20,\n",
    "                                                    batch_size = 32*10,\n",
    "                                                    step = 60,\n",
    "                                                    mod = 10000,\n",
    "                                                    gamma = 0.9,\n",
    "                                                    prob = 0.5\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04407758 0.00122013]\n",
      "[0.04406762 0.0012188 ]\n",
      "[0.04406039 0.00122745]\n",
      "[0.04403926 0.00123698]\n",
      "[0.04401226 0.00124855]\n",
      "[0.04399534 0.00127187]\n",
      "[0.044003   0.00128542]\n",
      "[0.0440254  0.00128479]\n",
      "[0.04406096 0.00129932]\n",
      "[0.04409056 0.00130511]\n",
      "[0.04412295 0.00129533]\n",
      "[0.04414815 0.00128755]\n",
      "[0.04415967 0.00128826]\n",
      "[0.04415648 0.00127912]\n",
      "[0.04414176 0.00127773]\n",
      "[0.04413013 0.00127961]\n",
      "[0.04411468 0.0012868 ]\n",
      "[0.04408157 0.00128279]\n",
      "[0.04403638 0.00126987]\n",
      "[0.04397529 0.00127254]\n",
      "[0.04391447 0.00128809]\n",
      "[0.04386001 0.00128886]\n",
      "[0.04381664 0.00127745]\n",
      "[0.04376879 0.00124873]\n",
      "[0.0437334  0.00121147]\n",
      "[0.04370567 0.00118482]\n",
      "[0.04369316 0.001164  ]\n",
      "[0.04369225 0.00113843]\n",
      "[0.04370347 0.00112094]\n",
      "[0.04370598 0.00110098]\n",
      "[0.04370517 0.00107853]\n",
      "[0.0437019  0.00106236]\n",
      "[0.04370802 0.00103939]\n",
      "[0.04370724 0.00102051]\n",
      "[0.04370193 0.00100701]\n",
      "[0.04369649 0.00099259]\n",
      "[0.0437008  0.00097246]\n",
      "[0.04370239 0.00095339]\n",
      "[0.04369636 0.00093567]\n",
      "[0.04367495 0.00092299]\n",
      "[0.04366861 0.00091313]\n",
      "[0.0436772  0.00091122]\n",
      "[0.0436957  0.00090979]\n",
      "[0.04370979 0.00091053]\n",
      "[0.04371202 0.00091547]\n",
      "[0.0437137  0.00091941]\n",
      "[0.04371064 0.00092058]\n",
      "[0.04369925 0.00092243]\n",
      "[0.04369041 0.00091726]\n",
      "[0.04369191 0.00090569]\n",
      "[0.04370617 0.00089234]\n",
      "[0.04372071 0.00088079]\n",
      "[0.04373058 0.00087341]\n",
      "[0.04373153 0.00086883]\n",
      "[0.04373201 0.00086932]\n",
      "[0.04373929 0.00086922]\n",
      "[0.04375196 0.00086713]\n",
      "[0.0437668  0.00087184]\n",
      "[0.04377631 0.000877  ]\n",
      "[0.04378145 0.00087808]\n",
      "[0.04378437 0.00087554]\n",
      "[0.04378685 0.00087374]\n",
      "[0.04379155 0.00087306]\n",
      "[0.04379805 0.00087711]\n",
      "[0.04380214 0.00088356]\n",
      "[0.04380432 0.00089116]\n",
      "[0.04380332 0.00089756]\n",
      "[0.04380413 0.00090353]\n",
      "[0.04381021 0.00091399]\n",
      "[0.04382412 0.00092206]\n",
      "[0.04383999 0.00092938]\n",
      "[0.04385473 0.00093986]\n",
      "[0.04385949 0.00094597]\n",
      "[0.04386452 0.00095092]\n",
      "[0.04387173 0.00095762]\n",
      "[0.04388607 0.00096622]\n",
      "[0.04390286 0.0009762 ]\n",
      "[0.04391824 0.00099023]\n",
      "[0.04393294 0.00100765]\n",
      "[0.04394819 0.00102333]\n",
      "[0.04396209 0.00103676]\n",
      "[0.04397416 0.00104618]\n",
      "[0.04397897 0.00105651]\n",
      "[0.04397753 0.00106734]\n",
      "[0.04397073 0.00107825]\n",
      "[0.04396268 0.00108613]\n",
      "[0.04395159 0.00108946]\n",
      "[0.04393895 0.00108901]\n",
      "[0.04392054 0.00109176]\n",
      "[0.04389932 0.00109964]\n",
      "[0.0438801  0.00110598]\n",
      "[0.04386745 0.00110939]\n",
      "[0.04386035 0.00110909]\n",
      "[0.04385182 0.00110444]\n",
      "[0.04384267 0.0011042 ]\n",
      "[0.04383308 0.00110508]\n",
      "[0.04382434 0.00110478]\n",
      "[0.04381634 0.0010988 ]\n",
      "[0.04381028 0.00109077]\n",
      "[0.04380722 0.00108217]\n",
      "[0.04380828 0.00107083]\n",
      "[0.04381407 0.00106012]\n",
      "[0.04381847 0.00105212]\n",
      "[0.04381914 0.00104654]\n",
      "[0.04381916 0.00104447]\n",
      "[0.04381591 0.00104394]\n",
      "[0.04381201 0.00104588]\n",
      "[0.04380176 0.00104749]\n",
      "[0.04379012 0.00104439]\n",
      "[0.04378071 0.00103838]\n",
      "[0.04377751 0.00103486]\n",
      "[0.04378128 0.00103034]\n",
      "[0.04378708 0.00102501]\n",
      "[0.0437873  0.00102133]\n",
      "[0.04378197 0.00101633]\n",
      "[0.04377367 0.00101367]\n",
      "[0.04376683 0.00101194]\n",
      "[0.04376345 0.00100829]\n",
      "[0.04376403 0.00100412]\n",
      "[0.04376265 0.00099824]\n",
      "[0.04375977 0.00099291]\n",
      "[0.04375387 0.00098883]\n",
      "[0.04374925 0.00098247]\n",
      "[0.04374696 0.00097656]\n",
      "[0.04374434 0.00097315]\n",
      "[0.04374256 0.00097097]\n",
      "[0.04374386 0.00096867]\n",
      "[0.04374877 0.00096844]\n",
      "[0.04375682 0.00096842]\n",
      "[0.0437649  0.00096899]\n",
      "[0.04377439 0.00097079]\n",
      "[0.04378502 0.00097273]\n",
      "[0.04379509 0.00097582]\n",
      "[0.04380222 0.00097767]\n",
      "[0.04380383 0.00097774]\n",
      "[0.043803   0.00097769]\n",
      "[0.04380159 0.00097905]\n",
      "[0.04380014 0.00098238]\n",
      "[0.04379595 0.0009857 ]\n",
      "[0.0437897  0.00098811]\n",
      "[0.04378346 0.00098952]\n",
      "[0.04377849 0.00099089]\n",
      "[0.04377506 0.00099257]\n",
      "[0.04377265 0.00099595]\n",
      "[0.04377021 0.00099848]\n",
      "[0.04376714 0.00099906]\n",
      "[0.04376352 0.00099812]\n",
      "[0.04376286 0.00099432]\n",
      "[0.04376576 0.00099131]\n",
      "[0.04377039 0.00098949]\n",
      "[0.04377341 0.00099032]\n",
      "[0.04377357 0.00099189]\n",
      "[0.04377188 0.00099342]\n",
      "[0.04377123 0.00099285]\n",
      "[0.04377066 0.00098998]\n",
      "[0.04376858 0.00098672]\n",
      "[0.0437643  0.00098328]\n",
      "[0.04375859 0.00097917]\n",
      "[0.04375103 0.00097127]\n",
      "[0.04374154 0.00096269]\n",
      "[0.04373306 0.00095527]\n",
      "[0.04372516 0.00094894]\n",
      "[0.04371902 0.0009466 ]\n",
      "[0.04370952 0.00094684]\n",
      "[0.04369682 0.00094719]\n",
      "[0.04368559 0.00094187]\n",
      "[0.04367889 0.00093259]\n",
      "[0.04368157 0.0009237 ]\n",
      "[0.04368623 0.00091594]\n",
      "[0.04369118 0.0009086 ]\n",
      "[0.04369326 0.00090039]\n",
      "[0.04369358 0.00088946]\n",
      "[0.04369605 0.00087923]\n",
      "[0.04370266 0.00087053]\n",
      "[0.0437128  0.00086952]\n",
      "[0.04372533 0.00087196]\n",
      "[0.04373692 0.00087788]\n",
      "[0.04374495 0.00088391]\n",
      "[0.04374802 0.00088343]\n",
      "[0.04375097 0.00088147]\n",
      "[0.04375393 0.00087705]\n",
      "[0.04375828 0.00087199]\n",
      "[0.0437641 0.0008676]\n",
      "[0.04376746 0.00086134]\n",
      "[0.04376867 0.00085488]\n",
      "[0.04376585 0.00085262]\n",
      "[0.0437628  0.00085555]\n",
      "[0.04376015 0.00085956]\n",
      "[0.04376009 0.00086862]\n",
      "[0.04376391 0.00087813]\n",
      "[0.04377041 0.00088679]\n",
      "[0.04378273 0.00089164]\n",
      "[0.04379673 0.00089364]\n",
      "[0.04381003 0.00089571]\n",
      "[0.04381776 0.00089795]\n",
      "[0.04382418 0.00090034]\n",
      "[0.04383569 0.00089962]\n",
      "[0.04385285 0.00089866]\n",
      "[0.04387566 0.00089918]\n",
      "[0.04389331 0.00090189]\n",
      "[0.04390528 0.00091332]\n",
      "[0.04391184 0.00092807]\n",
      "[0.04391712 0.00094462]\n",
      "[0.04392299 0.00095544]\n",
      "[0.04392632 0.00096503]\n",
      "[0.04392809 0.00097481]\n",
      "[0.04392916 0.00098345]\n",
      "[0.04393043 0.00099166]\n",
      "[0.0439343  0.00100107]\n",
      "[0.04393877 0.00101388]\n",
      "[0.04394538 0.00102604]\n",
      "[0.04395216 0.00103933]\n",
      "[0.04395887 0.00105006]\n",
      "[0.04396338 0.00105754]\n",
      "[0.0439698  0.00106357]\n",
      "[0.04397259 0.00106911]\n",
      "[0.04397625 0.00107659]\n",
      "[0.04397555 0.0010811 ]\n",
      "[0.04396849 0.00108647]\n",
      "[0.04395437 0.00109144]\n",
      "[0.04393256 0.00109491]\n",
      "[0.04391623 0.0011011 ]\n",
      "[0.04390692 0.00110719]\n",
      "[0.04390623 0.00111274]\n",
      "[0.04390882 0.00111708]\n",
      "[0.04390819 0.00112217]\n",
      "[0.04390741 0.00112724]\n",
      "[0.04390603 0.00112857]\n",
      "[0.04390676 0.0011277 ]\n",
      "[0.0439068  0.00112375]\n",
      "[0.04390588 0.00112079]\n",
      "[0.04390304 0.00111868]\n",
      "[0.04389894 0.0011177 ]\n",
      "[0.04389447 0.00111897]\n",
      "[0.04388753 0.00111973]\n",
      "[0.04387937 0.00111819]\n",
      "[0.04386723 0.00111736]\n",
      "[0.04385418 0.00111753]\n",
      "[0.0438431  0.00111381]\n",
      "[0.04383179 0.00110637]\n",
      "[0.04382044 0.00109353]\n",
      "[0.0438068  0.00108102]\n",
      "[0.04379325 0.00107351]\n",
      "[0.04378072 0.00106566]\n",
      "[0.04376998 0.00105837]\n",
      "[0.04375959 0.00104962]\n",
      "[0.0437495  0.00104125]\n",
      "[0.04374259 0.00103544]\n",
      "[0.04373844 0.00102944]\n",
      "[0.04373892 0.00102214]\n",
      "[0.04373843 0.00101658]\n",
      "[0.04373562 0.00100822]\n",
      "[0.04373224 0.00099887]\n",
      "[0.04372988 0.00099102]\n",
      "[0.04373035 0.00098386]\n",
      "[0.04373151 0.00097806]\n",
      "[0.04373318 0.00097232]\n",
      "[0.04373759 0.00096701]\n",
      "[0.04374669 0.00096428]\n",
      "[0.04375585 0.00096133]\n",
      "[0.0437634  0.00096008]\n",
      "[0.04376315 0.00096019]\n",
      "[0.04376015 0.00095979]\n",
      "[0.04375659 0.00095952]\n",
      "[0.04375151 0.00095971]\n",
      "[0.04374546 0.00095859]\n",
      "[0.04373843 0.00095616]\n",
      "[0.04373152 0.00095305]\n",
      "[0.04372533 0.00094876]\n",
      "[0.04371966 0.00094412]\n",
      "[0.04371735 0.00093906]\n",
      "[0.04371596 0.00093535]\n",
      "[0.04371362 0.00093302]\n",
      "[0.04370738 0.00093028]\n",
      "[0.0436988  0.00092609]\n",
      "[0.04368805 0.00091922]\n",
      "[0.04367882 0.0009118 ]\n",
      "[0.04367084 0.00090374]\n",
      "[0.04365865 0.00089522]\n",
      "[0.043646   0.00088426]\n",
      "[0.04363219 0.00086705]\n",
      "[0.04362145 0.00084849]\n",
      "[0.0436142  0.00083329]\n",
      "[0.04360922 0.0008217 ]\n",
      "[0.04360397 0.0008106 ]\n",
      "[0.04359876 0.00079523]\n",
      "[0.04359773 0.00077859]\n",
      "[0.04360829 0.00076354]\n",
      "[0.04362502 0.00075505]\n",
      "[0.0436445  0.00075371]\n",
      "[0.04366478 0.00075567]\n",
      "[0.04368323 0.00075737]\n",
      "[0.04370195 0.00076046]\n",
      "[0.0437206  0.00075969]\n",
      "[0.04373806 0.00075977]\n",
      "[0.04375622 0.00075774]\n",
      "[0.04377571 0.0007491 ]\n",
      "[0.04379491 0.00073641]\n",
      "[0.04380816 0.0007177 ]\n",
      "[0.04381043 0.00070885]\n",
      "[0.04380837 0.00070724]\n",
      "[0.04379965 0.00070982]\n",
      "[0.04378928 0.00072026]\n",
      "[0.04377217 0.0007338 ]\n",
      "[0.04375199 0.00074882]\n",
      "[0.04373515 0.00076272]\n",
      "[0.04373441 0.00077664]\n",
      "[0.04374931 0.00078026]\n",
      "[0.04377023 0.00077833]\n",
      "[0.04379012 0.00077588]\n",
      "[0.04380815 0.00077383]\n",
      "[0.04383468 0.00077128]\n",
      "[0.04386548 0.00077081]\n",
      "[0.04389627 0.00077539]\n",
      "[0.043921   0.00078474]\n",
      "[0.04393777 0.00080451]\n",
      "[0.04395412 0.00083178]\n",
      "[0.04396432 0.00085697]\n",
      "[0.0439696  0.00086813]\n",
      "[0.04396974 0.00086621]\n",
      "[0.04396354 0.00086791]\n",
      "[0.04395292 0.00087135]\n",
      "[0.04394009 0.000869  ]\n",
      "[0.04392955 0.00086433]\n",
      "[0.04391082 0.00085486]\n",
      "[0.04389171 0.00084844]\n",
      "[0.04387691 0.0008572 ]\n",
      "[0.04386986 0.00086347]\n",
      "[0.04387016 0.00086481]\n",
      "[0.04387158 0.00086596]\n",
      "[0.04386704 0.00085997]\n",
      "[0.04386537 0.00084749]\n",
      "[0.04386951 0.00083163]\n",
      "[0.04387623 0.00081509]\n",
      "[0.04387025 0.00080214]\n",
      "[0.04385546 0.0007914 ]\n",
      "[0.04384325 0.00077151]\n",
      "[0.04384328 0.00074837]\n",
      "[0.04385683 0.00073141]\n",
      "[0.04387551 0.00071857]\n",
      "[0.04389447 0.00071283]\n",
      "[0.04391473 0.00071186]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04393334 0.00071732]\n",
      "[0.0439418  0.00071703]\n",
      "[0.04393406 0.00071927]\n",
      "[0.0439245  0.00072074]\n",
      "[0.04392512 0.00072125]\n",
      "[0.04393944 0.00072145]\n",
      "[0.0439623  0.00072514]\n",
      "[0.04398618 0.00073275]\n",
      "[0.04401466 0.00073906]\n",
      "[0.04404667 0.00074529]\n",
      "[0.04408318 0.00075661]\n",
      "[0.04411921 0.00077648]\n",
      "[0.04415547 0.00080071]\n",
      "[0.04419108 0.00082429]\n",
      "[0.04422252 0.00084544]\n",
      "[0.04424602 0.00086603]\n",
      "[0.0442671  0.00089097]\n",
      "[0.04428804 0.00091411]\n",
      "[0.04430196 0.00094307]\n",
      "[0.04430968 0.00096675]\n",
      "[0.04431307 0.00098725]\n",
      "[0.04431602 0.00099333]\n",
      "[0.04431604 0.00099203]\n",
      "[0.0443155  0.00099701]\n",
      "[0.04431107 0.00100852]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-527da0b458cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0myolo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchikas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mperfection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperfect_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-527da0b458cd>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(iterations, dataset)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# random walk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_trans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_trans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0ma_is_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/data2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       return training_arrays.predict_loop(\n\u001b[0;32m-> 1113\u001b[0;31m           self, x, batch_size=batch_size, verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/data2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/data2/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/.conda/envs/data2/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def run(iterations, dataset):\n",
    "    values = []\n",
    "    for iteration in range(iterations):\n",
    "        cash = [1000]\n",
    "        position = [0]\n",
    "        value =[1000]\n",
    "        for t in range(len(data)- 60):\n",
    "            # define current environment/state (s) and next environment (s1)\n",
    "            s = dataset[t:t+60]\n",
    "            s_trans = np.expand_dims(np.array([s]),2)\n",
    "            s1 = dataset[t+1:t+61]\n",
    "            # update cash and position metrics\n",
    "            def a_is_0():\n",
    "                if cash[-1] == 0:\n",
    "                    cash.append(position[-1]*s[-1])\n",
    "                    position.append(0)\n",
    "                    value.append(cash[-1])\n",
    "                else:\n",
    "                    cash.append(cash[-1])\n",
    "                    position.append(0)\n",
    "                    value.append(cash[-1])\n",
    "            def a_is_1():\n",
    "                if position[-1] == 0:\n",
    "                    position.append(cash[-1]/s[-1])\n",
    "                    cash.append(0)\n",
    "                    value.append(position[-1]*s[-1])\n",
    "                else:\n",
    "                    position.append(position[-1])\n",
    "                    value.append(position[-1]*s[-1])\n",
    "\n",
    "            # random walk\n",
    "            a = np.argmax(model_predict.predict(s_trans)[0])\n",
    "            print(model_predict.predict(s_trans)[0])\n",
    "            if a == 0:\n",
    "                a_is_0()\n",
    "            else:\n",
    "                a_is_1()\n",
    "        values.append(np.mean(value))\n",
    "    return values, value\n",
    "\n",
    "yolo, chikas = run(1,data)\n",
    "perfection, full = perfect_run(1, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc9fc331780>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(np.arange(0,len(chikas),1),chikas)\n",
    "sns.lineplot(np.arange(0,len(full),1),full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
